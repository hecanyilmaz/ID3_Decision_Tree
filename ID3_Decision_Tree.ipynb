{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165d6c3a",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f823e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34127198",
   "metadata": {},
   "source": [
    "### Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522192c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffles the whole data\n",
    "def shuffle_array(arr):\n",
    "    np.random.seed(1337)\n",
    "    l = len(arr)\n",
    "    for i in range(0,l):\n",
    "        index = np.random.randint(0, l)\n",
    "        arr[i] = arr[index]\n",
    "        \n",
    "#Splits train and test datasets\n",
    "def split_train_test(arr, targetCol, k_fold = 1):\n",
    "    \n",
    "    # k_fold: k value for k_fold cross validation\n",
    "    # dropCols: indices of the columns those are going to be dropped\n",
    "    # targetCol: target column or attribute\n",
    "    # Return type: list of X_train, y_train, X_test, y_test\n",
    "    \n",
    "    #Preparing data\n",
    "    shuffle_array(arr)\n",
    "    test_size = int(len(arr) / k_fold)\n",
    "    k_datasets = list()\n",
    "    \n",
    "    #Splitting dataset with respect to the k-fold Cross Validation\n",
    "    for index in range(k_fold):\n",
    "        test_array = arr[test_size * index: test_size * (index + 1)]\n",
    "        train_array = np.delete(arr, slice(test_size * index, test_size * (index + 1)), 0)\n",
    "        X_train = train_array\n",
    "        y_train = train_array[:, [targetCol]]\n",
    "        X_test = test_array\n",
    "        y_test = test_array[:, [targetCol]]\n",
    "        k_datasets.append([X_train, y_train, X_test, y_test])\n",
    "        \n",
    "    return k_datasets\n",
    "\n",
    "#Discretisation of continuous attributes\n",
    "def discretisation(data, continuousCols):\n",
    "    max_ele, min_ele = data.max(axis = 0), data.min(axis = 0)\n",
    "    for i in continuousCols:\n",
    "        mx, mn = max_ele[i], min_ele[i]\n",
    "        wide = math.ceil((mx - mn) / 5) #5 intervals\n",
    "        for row in data:\n",
    "            x = (row[i] - mn) // wide\n",
    "            ticket = \"{} - {}\".format((x * wide + mn), ((x+1) * wide + mn - 1))\n",
    "            row[i] = ticket\n",
    "\n",
    "#Returns counts of unique values of an attribute                \n",
    "def count_unique_values(data, col_index):\n",
    "    attr = data[:, col_index]\n",
    "    values, counts = np.unique(attr, return_counts = True)\n",
    "    return values, counts\n",
    "\n",
    "#Returns entropy of an attribute\n",
    "def entropy(data, col_index):\n",
    "    total = 0\n",
    "    _ , counts = count_unique_values(data, col_index)\n",
    "    for count in counts:\n",
    "        proportion = count / len(data)\n",
    "        total -= (proportion)*np.log2(proportion)\n",
    "    return total\n",
    "\n",
    "#Returns information gain of an attribute\n",
    "def info_gain(data, col_index, target_index):\n",
    "    gain = entropy(data, target_index)\n",
    "    values, _ = count_unique_values(data, col_index)\n",
    "    for i in range(len(values)):\n",
    "        mask = (data[:, col_index] == values[i])\n",
    "        value_data = data[mask, :]\n",
    "        gain -= (len(value_data) / len(data)) * entropy(value_data, target_index)\n",
    "    return gain\n",
    "\n",
    "#Node class\n",
    "class node(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.children = [] #References to child nodes\n",
    "        self.attribute = None #Attribute name\n",
    "        self.leafNode = None #Leaf node or not\n",
    "        self.label = None\n",
    "        self.value = None\n",
    "        \n",
    "    def set_leafNode(self, b):\n",
    "        self.leafNode = b\n",
    "        \n",
    "    def get_leafNode(self):\n",
    "        return self.leafNode\n",
    "        \n",
    "    def set_label(self, tag):\n",
    "        self.label = tag\n",
    "        \n",
    "    def get_label(self):\n",
    "        return self.label\n",
    "        \n",
    "    def get_attribute(self):\n",
    "        return self.attribute\n",
    "        \n",
    "    def set_attribute(self, attribute):\n",
    "        self.attribute = attribute\n",
    "    \n",
    "    def set_children(self, children):\n",
    "        self.children = children\n",
    "        \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def set_value(self, v):\n",
    "        self.value = v\n",
    "        \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "              \n",
    "#ID3 Decision Tree Algorithm\n",
    "def id3(data, target_attr, attr):\n",
    "    \n",
    "    root = node()\n",
    "    values, counts = count_unique_values(data, target_attr)\n",
    "    \n",
    "    #If all examples are positive or negative\n",
    "    if (len(values) == 1):\n",
    "        root.set_leafNode(True)\n",
    "        root.set_label(values[0])\n",
    "    \n",
    "    #If attributes is empty, return most common most common value of target_attribute in data\n",
    "    elif (len(attr) == 0):\n",
    "        root.set_leafNode(True)\n",
    "        most_common_val_index = [index for index, item in enumerate(counts) if item == max(counts)][0]\n",
    "        root.set_label(values[most_common_val_index])\n",
    "    \n",
    "    #Otherwise\n",
    "    else:\n",
    "        #Finding best classifier attribute for the root node\n",
    "        info_gains = dict()\n",
    "        for a in attr:\n",
    "            info_gains[a] = info_gain(data, attr_dict[a], target_attr)\n",
    "        sorted_info_gains = sorted(info_gains.items(), key=lambda x: x[1], reverse=True)\n",
    "        best_classifier = sorted_info_gains[0][0]\n",
    "        best_classifier_index = attr_dict[best_classifier]\n",
    "        \n",
    "        #Root node set-up\n",
    "        root.set_leafNode(False)\n",
    "        attr.remove(best_classifier)\n",
    "        root.set_attribute(best_classifier)\n",
    "        \n",
    "        #Finding values of the attribute\n",
    "        best_values, _ = count_unique_values(data, best_classifier_index)\n",
    "        \n",
    "        #Initialize children of the root node\n",
    "        children = [node() for i in range(len(best_values))]\n",
    "        \n",
    "        #Set up children\n",
    "        for val_index in range(len(best_values)):\n",
    "            #Select the rows with the specific value\n",
    "            mask = (data[:, best_classifier_index] == best_values[val_index])\n",
    "            sub_data = data[mask, :]\n",
    "            \n",
    "            #If the selected dataset is empty \n",
    "            if (len(sub_data) == 0):\n",
    "                children[val_index].set_leafNode(True)\n",
    "                most_common_val_index = [index for index, item in enumerate(counts) if item == max(counts)][0]\n",
    "                children[val_index].set_label(values[most_common_val_index])\n",
    "            \n",
    "            #If NOT\n",
    "            else:\n",
    "                children[val_index] = id3(sub_data, target_attr, attr)\n",
    "            \n",
    "            #Value of the children nodes\n",
    "            children[val_index].set_value(best_values[val_index])\n",
    "        \n",
    "        #Add children to the root node\n",
    "        root.set_children(children)\n",
    "        \n",
    "    #Return root\n",
    "    return root\n",
    "\n",
    "#Classify the sample with the ID3 tree\n",
    "def classify_id3(tree, sample):\n",
    "    #If the tree is leafNode\n",
    "    if (tree.get_leafNode() == True):\n",
    "        return tree.get_label()\n",
    "    \n",
    "    #If NOT\n",
    "    else:\n",
    "        #Which attribute need to be checked\n",
    "        attr = tree.get_attribute()\n",
    "        sample_attr_val = sample[attr_dict[attr]]\n",
    "        \n",
    "        #Check the specific attribute's values if that matches with sample's attribute\n",
    "        for child in tree.get_children():\n",
    "            if (child.get_value() == sample_attr_val):\n",
    "                return classify_id3(child, sample)\n",
    "        \n",
    "        return None\n",
    "\n",
    "class ID3:\n",
    "    \n",
    "    def __init__(self, train_data, test_data, y_test, classes, target_index, attribute_names):\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.y_test = y_test\n",
    "        self.classes = classes\n",
    "        self.target_index = target_index\n",
    "        self.attribute_names = attribute_names\n",
    "        self.confusionMatrix = np.zeros(shape=(len(classes),len(classes)), dtype=int)\n",
    "        \n",
    "        #classification part\n",
    "        tree = id3(self.train_data, self.target_index, self.attribute_names)\n",
    "        for i in range(len(self.test_data)):\n",
    "            predicted_class = classify_id3(tree, self.test_data[i])\n",
    "            if (predicted_class == None): continue\n",
    "            actual_class = self.y_test[i][0]\n",
    "            self.confusionMatrix[classes[predicted_class],classes[actual_class]] += 1\n",
    "            \n",
    "    def get_confusionMatrix(self):\n",
    "        return self.confusionMatrix\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        return np.trace(self.confusionMatrix) / np.sum(self.confusionMatrix) * 100\n",
    "        \n",
    "    def print_accuracy(self):\n",
    "        print(\"Accuracy: {:.2f}%\".format(self.get_accuracy()))\n",
    "                \n",
    "    def plot(self):\n",
    "        df_cm = pd.DataFrame(self.confusionMatrix, index = [i for i in self.classes], columns = [i for i in self.classes])\n",
    "        plt.figure(figsize = (7,7))\n",
    "        ax = sn.heatmap(df_cm, annot=True, fmt = \"d\", cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    "        ax.set(ylabel=\"Predicted Label\", xlabel=\"Actual Label\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.title(\"Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc43dd",
   "metadata": {},
   "source": [
    "### Data Preparing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparing parameters\n",
    "dropColumns = ['EmployeeNumber']\n",
    "targetColumn = 'Attrition'\n",
    "continuousColumns = ['Age', 'DailyRate', 'DistanceFromHome',\n",
    "                     'HourlyRate', 'MonthlyIncome', 'MonthlyRate',\n",
    "                     'NumCompaniesWorked', 'PercentSalaryHike', 'TotalWorkingYears',\n",
    "                     'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "                    'YearsWithCurrManager', 'TrainingTimesLastYear']\n",
    "attributeColumns = copy.deepcopy(dropColumns)\n",
    "attributeColumns.append(targetColumn)\n",
    "csv_file = 'HR-Employee-Attrition.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a0137d",
   "metadata": {},
   "source": [
    "### Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca21e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparing \n",
    "df = pd.read_csv(csv_file)\n",
    "df.drop(columns=dropColumns, inplace = True)\n",
    "target_index = df.columns.get_loc(targetColumn)\n",
    "#Preparing attribute dictionary and attribute names\n",
    "attr_dict = dict()\n",
    "for index in range(len(df.columns)):\n",
    "    attr_dict[df.columns[index]] = index\n",
    "#Dataframe to numpy\n",
    "arr = df.to_numpy()\n",
    "#Discretisation\n",
    "continuous_indices = [df.columns.get_loc(col_name) for col_name in continuousColumns]\n",
    "discretisation(arr, continuous_indices)\n",
    "#Classes\n",
    "classes, _ = count_unique_values(arr, target_index)\n",
    "classes_dict = {}\n",
    "for i in range(len(classes)):\n",
    "    classes_dict[classes[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06aef9",
   "metadata": {},
   "source": [
    "### k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2d9e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Fold Cross Validation, Fold Number: 0 Accuracy: 89.12%\n",
      "k-Fold Cross Validation, Fold Number: 1 Accuracy: 88.28%\n",
      "k-Fold Cross Validation, Fold Number: 2 Accuracy: 89.00%\n",
      "k-Fold Cross Validation, Fold Number: 3 Accuracy: 86.73%\n",
      "k-Fold Cross Validation, Fold Number: 4 Accuracy: 87.76%\n"
     ]
    }
   ],
   "source": [
    "kFold_list = split_train_test(arr, target_index, k_fold = 5)\n",
    "_ = 0\n",
    "\n",
    "for fold in kFold_list:\n",
    "    train_data = fold[0]\n",
    "    test_data = fold[2]\n",
    "    y_test = fold[3]\n",
    "    \n",
    "    attribute_names = [key for key in attr_dict.keys() if key not in attributeColumns]\n",
    "    ID3_obj = ID3(train_data, test_data, y_test, classes_dict, target_index, attribute_names)\n",
    "    print(\"k-Fold Cross Validation, Fold Number: {}\".format(_), end = \" \")\n",
    "    ID3_obj.print_accuracy()\n",
    "    _ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702184b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
